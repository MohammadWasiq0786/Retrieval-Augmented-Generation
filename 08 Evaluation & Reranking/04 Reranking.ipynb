{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d1ff23b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ff23b2",
        "outputId": "fa9e7511-7eb1-4994-cbab-caa46a54be63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q langchain faiss-cpu requests numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2bd19a1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bd19a1a",
        "outputId": "566504cd-1c35-4bf0-db7e-84e21eef7c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q euriai[langchain]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQZ1T-v0HjMV",
        "outputId": "233e43e5-a8d1-4e5b-e903-a0dcc4712680"
      },
      "id": "kQZ1T-v0HjMV",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EURI_API_KEY= \"euri-.....\""
      ],
      "metadata": {
        "id": "4pYAChmZHn34"
      },
      "id": "4pYAChmZHn34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2988882f",
      "metadata": {
        "id": "2988882f"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from langchain.embeddings.base import Embeddings\n",
        "\n",
        "class EuriaiEmbedding(Embeddings):\n",
        "    def __init__(self, api_key: str, model: str = \"text-embedding-3-small\"):\n",
        "        self.api_key = api_key\n",
        "        self.model = model\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        return [self.embed_query(text) for text in texts]\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        url = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
        "        }\n",
        "        payload = {\n",
        "            \"input\": text,\n",
        "            \"model\": self.model\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        embedding = np.array(response.json()[\"data\"][0][\"embedding\"]).tolist()\n",
        "        return embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "26154f80",
      "metadata": {
        "id": "26154f80"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    Document(page_content=\"EURI provides AI APIs for developers.\"),\n",
        "    Document(page_content=\"LangChain integrates LLMs with tools, memory, and agents.\"),\n",
        "    Document(page_content=\"The weather is sunny today.\"),\n",
        "    Document(page_content=\"FAISS is used for vector similarity search.\"),\n",
        "    Document(page_content=\"EURI embedding API returns dense vector representations.\")\n",
        "]\n",
        "\n",
        "# Initialize EURI embedding model\n",
        "euriai_embedder = EuriaiEmbedding(api_key= EURI_API_KEY)\n",
        "\n",
        "# Build FAISS index\n",
        "vectorstore = FAISS.from_documents(documents, euriai_embedder)\n",
        "retriever = vectorstore.as_retriever(k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bf4355df",
      "metadata": {
        "id": "bf4355df"
      },
      "outputs": [],
      "source": [
        "query = \"What is the use of EURI in AI?\"\n",
        "retrieved_docs = retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "90e74106",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90e74106",
        "outputId": "eeb31c8b-a533-4496-fc21-ad88f5f3a5cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='11b5d4af-27ea-4c5e-b207-f05adfe053ab', metadata={}, page_content='EURI provides AI APIs for developers.'),\n",
              " Document(id='4573e13f-5437-4c3c-a4c7-5b36f793b4d0', metadata={}, page_content='EURI embedding API returns dense vector representations.'),\n",
              " Document(id='690b1ac2-b227-4907-88b7-615c8952bab1', metadata={}, page_content='FAISS is used for vector similarity search.'),\n",
              " Document(id='c50b0ac5-dbb9-4be9-80d2-2ed2c0d3f5ea', metadata={}, page_content='LangChain integrates LLMs with tools, memory, and agents.')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e362519f",
      "metadata": {
        "id": "e362519f"
      },
      "outputs": [],
      "source": [
        "from euriai.langchain import create_chat_model\n",
        "\n",
        "chat_model = create_chat_model(\n",
        "    api_key= EURI_API_KEY,\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "def rerank_with_euri(query, docs):\n",
        "    scored = []\n",
        "    for doc in docs:\n",
        "        prompt = (\n",
        "            f\"Rate relevance (0-10) for this document:\\n\\n\"\n",
        "            f\"Query: {query}\\n\"\n",
        "            f\"Document: {doc.page_content}\\n\"\n",
        "            f\"Answer only with a number:\"\n",
        "        )\n",
        "        response = chat_model.invoke(prompt)\n",
        "        try:\n",
        "            score = float(response.content.strip().split()[0])\n",
        "        except:\n",
        "            score = 0.0\n",
        "        scored.append((doc, score))\n",
        "    reranked = sorted(scored, key=lambda x: x[1], reverse=True)\n",
        "    return [doc for doc, _ in reranked]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ec162c02",
      "metadata": {
        "id": "ec162c02"
      },
      "outputs": [],
      "source": [
        "reranked_docs = rerank_with_euri(query, retrieved_docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "acd81c5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acd81c5a",
        "outputId": "d4d1afb3-ade5-4066-e76c-17b3aae0a24c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='11b5d4af-27ea-4c5e-b207-f05adfe053ab', metadata={}, page_content='EURI provides AI APIs for developers.'),\n",
              " Document(id='4573e13f-5437-4c3c-a4c7-5b36f793b4d0', metadata={}, page_content='EURI embedding API returns dense vector representations.'),\n",
              " Document(id='690b1ac2-b227-4907-88b7-615c8952bab1', metadata={}, page_content='FAISS is used for vector similarity search.'),\n",
              " Document(id='c50b0ac5-dbb9-4be9-80d2-2ed2c0d3f5ea', metadata={}, page_content='LangChain integrates LLMs with tools, memory, and agents.')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "reranked_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cf700e49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf700e49",
        "outputId": "1ecc9032-fd49-4fb6-811b-6b5eb3624cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💬 Final Answer:\n",
            "EURI provides AI APIs that enable developers to incorporate advanced functionalities such as generating dense vector embeddings, which are useful for tasks like similarity search, clustering, and retrieval. Specifically, the EURI embedding API transforms textual or other data into high-dimensional vector representations that can be efficiently stored and searched using tools like FAISS. Additionally, when integrated with frameworks like LangChain, EURI's APIs facilitate building sophisticated AI applications that leverage large language models alongside vector-based retrieval and memory components.\n"
          ]
        }
      ],
      "source": [
        "# Create context\n",
        "context = \"\\n\".join([doc.page_content for doc in reranked_docs])\n",
        "\n",
        "# Ask LLM to answer\n",
        "final_prompt = f\"\"\"You are an expert assistant.\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "Answer:\"\"\"\n",
        "\n",
        "response = chat_model.invoke(final_prompt)\n",
        "print(\"\\n💬 Final Answer:\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c52b8b",
      "metadata": {
        "id": "05c52b8b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lang_graph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}